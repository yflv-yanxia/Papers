# Papers
## layout
  [Page segmentation using convolutional neural network and graphical model](https://link.springer.com/chapter/10.1007/978-3-030-57058-3_17) -Lixiaohui, DAS2020<br>
  [Printed/Handwritten Texts and Graphics Separation in Complex Documents Using Conditional Random Fields](https://ieeexplore.ieee.org/abstract/document/8395186) -LiXiaohui, DAS2018<br> 

## asr
  [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100) -google, Interspeech2020, [code1](https://github.com/sooftware/conformer),[code2](https://github.com/thu-spmi/CAT)<br>
  [ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context](https://arxiv.org/abs/2005.03191) -google, Interspeech2020, [code](https://github.com/hasangchun/ContextNet)<br>
  [Investigation of modeling units for mandarin speech recognition using DFSMN-CTC-sMBR](https://ieeexplore.ieee.org/abstract/document/8683859) -alibaba, ICASSP2019<br>
  [Sequence discriminative distributed training of long short-term memory recurrent neural networks](https://research.google/pubs/pub42547/) -google, <br>
  [Sequence-discriminative training of deep neural networks](http://www.fit.vutbr.cz/research/groups/speech/publi/2013/vesely_interspeech2013_IS131333.pdf) INTERSPEECH2013<br>

## Contextual Biasing
  [Improved recognition of contact names in voice commands]() -google, ICASSP2015<br>
  [Bringing contextual information to google speech recognition](https://www.semanticscholar.org/paper/Bringing-contextual-information-to-google-speech-Aleksic-Ghodsi/740844739cd791e9784c4fc843beb9174ed0b487?p2df) -google, INTERSPEECH2015<br>
  [Shallow-Fusion End-to-End Contextual Biasing]() -google, INTERSPEECH2019<br>
  [Streaming End-to-end Speech Recognition for Mobile Devices](https://arxiv.org/abs/1811.06621) -google, ICASSP2019<br>
  
## table detection & recognition
  [Robust Table Detection and Structure Recognition from Heterogeneous Document Images](https://arxiv.org/abs/2203.09056) -huoqiang, arxiv2022<br>
  [Deep Structured Feature Networks for Table Detection and Tabular Data Extraction from Scanned Financial Document Images](https://arxiv.org/abs/2102.10287) -arxiv2021<br>
  [Guided Table Structure Recognition through Anchor Optimization](https://arxiv.org/abs/2104.10538) -arxiv2021<br>
  [TabAug: Data Driven Augmentation for Enhanced Table Structure Recognition](https://arxiv.org/abs/2104.14237) -ICDAR2021<br>
  [PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Table Image Recognition to Latex](https://arxiv.org/abs/2105.01846) -pingan, arxiv2021<br>
  [LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment](https://arxiv.org/abs/2105.06224) -ICDAR2021<br>
  [ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX](https://arxiv.org/abs/2105.14426) -arxiv2021<br>
  [TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition](https://arxiv.org/abs/2106.10598) JD-ICCV2021, [code](https://github.com/xuewenyuan/TGRNet)<br>
  [Parsing Table Structures in the Wild](https://arxiv.org/abs/2109.02199) -alibaba, ICCV2021, [dataset](https://github.com/wangwen-whu/WTW-Dataset)<br>
  [TNCR: Table Net Detection and Classification Dataset](https://github.com/abdoelsayed2016/TNCR_Dataset) -arxiv2021, [dataset](https://github.com/abdoelsayed2016/TNCR_Dataset)<br>
  [Form2Seq : A Framework for Higher-Order Form Structure Extraction](https://arxiv.org/abs/2107.04419) -EMNLP2020<br>
  [Table Structure Recognition using Top-Down and Bottom-Up Cues](https://arxiv.org/abs/2010.04565) ECCV2020<br>
  [Tablenet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images](https://arxiv.org/abs/2001.01469) -ICDAR2019<br>
  [Image-based table recognition: data, model, and evaluation](https://arxiv.org/abs/1911.10683) -arxiv2019<br>
  [Deep Splitting and Merging for Table Structure Decomposition](https://ieeexplore.ieee.org/document/8977975) -ICDAR2019<br>
  [Deepdesrt: Deep learning for detection and structure recognition of tables in document images](https://ieeexplore.ieee.org/abstract/document/8270123) -ICDAR2017<br>
  
## mathematical expression recognition
  [Graph-to-graph: towards accurate and interpretable online handwritten mathematical expression recognition](https://ojs.aaai.org/index.php/AAAI/article/view/16399) -wujinwen, AAAI2021<br>
  [ICFHR 2020 Competition on Offline Recognition and Spotting of Handwritten Mathematical Expressions - OffRaSHME](https://ieeexplore.ieee.org/abstract/document/9257745) -Wangdahan, ICFHR2020<br>
  [Improvement of End-to-End Offline Handwritten Mathematical Expression Recognition by Weakly Supervised Learning](https://ieeexplore.ieee.org/abstract/document/9257749) -ICFHR2020<br>
  [Improving Attention-Based Handwritten Mathematical Expression Recognition with Scale Augmentation and Drop Attention](https://ieeexplore.ieee.org/abstract/document/9257765) -Jinlianwen, ICFHR2020<br>
  [EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for Printed Mathematical Expression Recognition](https://arxiv.org/abs/2007.02517) -arxiv2020, [code](https://github.com/abcAnonymous/EDSL)<br>
  [Handwritten mathematical expression recognition via paired adversarial learning](https://link.springer.com/article/10.1007%2Fs11263-020-01291-5) -WuJinwen, IJCV2020<br>
  [Stroke Constrained Attention Network for Online Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2002.08670) -DuJun, arxiv2020, [code]()<br>
  [SRD: A Tree Structure Based Decoder for Online Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/9147045/) -DuJun, TMM2020, [code](https://github.com/Rid7/SRD)<br>
  [A Tree-Structured Decoder for Image-to-Markup Generation]() -Dujun, ICML2020, [code](https://github.com/JianshuZhang/TreeDecoder)<br>
  [Multi-modal Attention Network for Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/8978103/) -DuJun, ICDAR2019<br>
  [Robust Encoder-Decoder Learning Framework towards Offline Handwritten Mathematical Expression Recognition Based on Multi-Scale Deep Neural Network](https://arxiv.org/abs/1902.05376)-arxiv2019<br>
  [Track, attend, and parse (tap): An end-to-end framework for online handwritten mathematical expression recognition](https://ieeexplore.ieee.org/abstract/document/8373726) -DuJun, TMM2018, [code](https://github.com/JianshuZhang/TAP)<br>
  [Multi-scale attention with dense encoder for handwritten mathematical expression recognition](https://ieeexplore.ieee.org/abstract/document/8546031) -DuJun, ICPR2018, [code](https://github.com/JianshuZhang/WAP)<br>
  [Watch, attend and parse: An end-to-end neural network based approach to handwritten mathematical expression recognition](https://www.sciencedirect.com/science/article/pii/S0031320317302376) -J Zhang, J Du, S Zhang, D Liu, Y Hu, J Hu, S Wei, PR2017, [code](https://github.com/JianshuZhang/WAP), [code2](https://github.com/whywhs/Pytorch-Handwritten-Mathematical-Expression-Recognition)<br>
  [A GRU-Based Encoder-Decoder Approach with Attention for Online Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/8270083) -Dujun, ICDAR2017, [code](https://github.com/JianshuZhang/TAP)<br>
  [Image-to-markup generation with coarse-to-fine attention](http://proceedings.mlr.press/v70/deng17a.html) -Dengyuntian, ICML2017, [code](https://github.com/harvardnlp/im2markup/)<br>
  [What you get is what you see: A visual markup decompiler](https://arxiv.org/abs/1609.04938) -Dengyuntian, arxiv2016, [code](https://github.com/OpenNMT/OpenNMT-py/blob/master/docs/source/legacy/im2text.md)<br>
  [Context-aware mathematical expression recognition: An end-to-end framework and a benchmark](https://ieeexplore.ieee.org/abstract/document/7900135) -Hewenhao, ICPR2016<br>
  [ICFHR2016 CROHME: Competition on Recognition of Online Handwritten Mathematical Expressions](https://ieeexplore.ieee.org/abstract/document/7814132) -ICFHR2016<br>
  [An integrated grammar-based approach for mathematical expression recognition](https://www.sciencedirect.com/science/article/abs/pii/S0031320315003441) -PR2016<br>
## word_vector
  [Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)--FAIR, arxiv2016<br>
  [fastText-Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759)-FAIR, arxiv2016<br>
  [An empirical evaluation of doc2vec with practical insights into document embedding generation](https://arxiv.org/abs/1607.05368)-Jey Han Lau, Timothy Baldwin, arxiv2016<br>
  [TagSpace：Semantic Embeddings from Hashtags](http://www.aclweb.org/anthology/D14-1194)-FAIR, EMNLP2014<br>
  [doc2vec-Distributed Representations of Sentences and Documents](http://proceedings.mlr.press/v32/le14.pdf)-google, ICML2014<br>
  [word2vec-Efficient estimation of word representations in vector space](https://arxiv.org/abs/1301.3781)-google, ICLR2013<br>
  
## Seq2Seq
  [Convolutional Sequence to Sequence Learning](https://arxiv.org/abs/1705.03122) -FAIR, arxiv2017<br>
  [A Convolutional Encoder Model for Neural Machine Translation](https://arxiv.org/abs/1611.02344)-FAIR, arxiv2016<br>
  [Sequence level training with recurrent neural networks](https://arxiv.org/abs/1511.06732)-FAIR, ICLR2016<br>
  
## ReID
  [Alignedreid: Surpassing human-level performance in person re-identification](https://arxiv.org/abs/1711.08184) -Face++, arxiv2017<br>

## PoseEstimation
  [Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1611.08050) -CMU, CVPR2017<br>
  AlphaPose<br>
## EdgeDetection
  [Deepedge: A multi-scale bifurcated deep network for top-down contour detection](https://www.seas.upenn.edu/~gberta/uploads/3/1/4/8/31486883/1950.pdf) -Gedas, CVPR15<br>
  [Richer Convolutional Features for Edge Detection](http://mftp.mmcheng.net/Papers/19PamiEdge.pdf) -YunLiu, ..., Baixiang et, PAMI2019<br>
## video_classification
  [Learnable pooling with Context Gating for video classification](https://arxiv.org/abs/1706.06905) -A. Miech, et al, TPAMI2018, Youtube8M-Competition-Top1<br>
  [Truly Multi-modal YouTube-8M Video Classification with Video, Audio, and Text](https://arxiv.org/abs/1706.05461) -Zhe wang, et al, arxiv2017<br>
  
## dnn_base
[Group Normalization](https://arxiv.org/abs/1803.08494) -Kaiming He, et al, arxiv2018<br>
[Graph Convolutional Network](https://arxiv.org/abs/1803.08035) -Xiaolong Wang, Yufei Ye, Abhinav Gupta, CVPR2018<br>
DetNAS: Backbone Search for Object Detection<br>
Mixup<br>

## light network
TinyNet[Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets](https://arxiv.org/abs/2010.14819) -huawei, NeurIPS2020<br>
[GhostNet: More Features from Cheap Operations](https://arxiv.org/abs/1911.11907) -huawei, CVPR2020<br>
EfficientNet<br>
SqueezeNet<br>
[Mobilenets](https://arxiv.org/abs/1704.04861) -google, arxiv2017<br>
[MobileNet-V2](https://arxiv.org/abs/1801.04381) -google, CVPR2018 [caffe-code](https://github.com/austingg/MobileNet-v2-caffe)<br>
MobileNetV3<br>
[NasNet-A-Learning transferable architectures for scalable image recognition](https://arxiv.org/abs/1707.07012) -google brain, CoRR2017<br>
[ShuffleNet](https://arxiv.org/abs/1707.01083) -megvii, CoRR2017<br>
ShuffleNetV2<br>
ThunderNet<br>
DarkNet/Tiny YOLOv3/Tiny YOLOv2/Yolo-Nano/SlimYOLO/YOLO-LITE/Gaussian YOLOv3<br>
[LightweightNet: Toward fast and lightweight convolutional neural networks via architecture distillation](https://www.sciencedirect.com/science/article/abs/pii/S0031320318303807) -XuTingbin, PR2019<br>
Mobilefacenets<br>
EXTD: Extremely Tiny Face Detector via Iterative Filter Reuse<br>
Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution<br>
HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs<br>
Joint Architecture and Knowledge Distillation in Convolutional Neural Network for Offline Handwritten Chinese Text Recognition -dujun, arxiv2019
Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition -huoqiang, PR2019
[vovnet](https://arxiv.org/abs/1904.09730)<br>
http://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Lee_An_Energy_and_GPU-Computation_Efficient_Backbone_Network_for_Real-Time_Object_CVPRW_2019_paper.pdf


## model compression
蒸馏：teacher-student/mutual-learning/Self-Distillation<br>
张量分解：low-rank/SVD-decomposition/Tucker-decomposition/CP-decomposition<br>
剪枝<br>
量化<br>
编码<br>

## InformationExtraction
[LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) -microsoft, arxiv2022, [code](https://github.com/microsoft/unilm/tree/master/layoutlmv3)<br>
[DocFormer: End-to-End Transformer for Document Understanding](https://openaccess.thecvf.com/content/ICCV2021/html/Appalaraju_DocFormer_End-to-End_Transformer_for_Document_Understanding_ICCV_2021_paper.html) -amazon, ICCV2021<br>
[LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis](https://link.springer.com/chapter/10.1007/978-3-030-86549-8_9) -ICDAR2021<br>
[Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer](https://arxiv.org/abs/2102.09550) -ICDAR2021<br>
[Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution](https://arxiv.org/abs/2102.06732) -jinlianwen, AAAI2021<br>
[TRIE: End-to-End Text Reading and Information Extraction for Document Understanding](https://arxiv.org/abs/2005.13118) -hikvision, arxiv2020<br>
[LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) -microsoft, ACL2021, [code](https://github.com/microsoft/unilm/tree/master/layoutlmv2)<br>
[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) -microsoft, KDD2020, [code](https://github.com/microsoft/unilm/tree/master/layoutlm)<br>

## knowledge distillation
[Decoupled Knowledge Distillation](https://arxiv.org/abs/2203.08679) -megvii, CVPR2022, [code](https://github.com/megvii-research/mdistiller)<br>
[Efficient knowledge distillation for rnn-transducer models](https://ieeexplore.ieee.org/abstract/document/9413905) -google/facebook, ICASSP2021<br>
[Investigation of Sequence-level Knowledge Distillation Methods for CTC Acoustic Models](https://ieeexplore.ieee.org/document/8682671) -NICT japan, ICASSP2019<br>
[Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation](https://arxiv.org/abs/1904.08311) -IBM, Interspeech2019<br>
[Explaining sequence-level knowledge distillation as data-augmentation for neural machine translation](https://arxiv.org/abs/1912.03334) -arxiv2019<br>
[Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion](https://arxiv.org/abs/1904.03446) -microsoft, Interspeech2019<br>
[Knowledge Distillation for Sequence Model](https://www.researchgate.net/publication/327389374_Knowledge_Distillation_for_Sequence_Model) -AISpeech, Interspeech2018<br>
[Improved knowledge distillation from bi-directional to uni-directional LSTM CTC for end-to-end speech recognition](https://ieeexplore.ieee.org/abstract/document/8639629) -IBM, SLT2018<br>
[An Investigation of a Knowledge Distillation Method for CTC Acoustic Models](https://ieeexplore.ieee.org/document/8461995) -NICT japan, ICASSP2018<br>
[Sequence-Level Knowledge Distillation](https://arxiv.org/abs/1606.07947) -Yoon Kim, EMNLP2016<br>

## Document Rectification
[Fourier Document Restoration for Robust Document Dewarping and Recognition](http://arxiv-export-lb.library.cornell.edu/abs/2203.09910) -CVPR2022, bai song [database](https://sg-vilab.github.io/event/warpdoc/)<br>
[Document Dewarping with Control Points](https://arxiv.org/abs/2203.10543) -ICDAR2021, [code&dataset](https://github.com/gwxie/Document-Dewarping-with-Control-Points)<br>
[Document Rectification and Illumination Correction using a Patch-based CNN](https://arxiv.org/abs/1909.09470) -SIGGRAPH2019, [code](https://github.com/HCIILAB/DocProj)<br>

## Graph
[Joint stroke classification and text line grouping in online handwritten documents with edge pooling attention networks](https://www.sciencedirect.com/science/article/abs/pii/S0031320321000467) -PR2021<br>
[A Comprehensive Survey on Graph Neural Networks](https://ieeexplore.ieee.org/abstract/document/9046288) -TNN2020<br>
[Contextual Stroke Classification in Online Handwritten Documents with Edge Graph Attention Networks](https://link.springer.com/article/10.1007/s42979-020-00177-0) -SNCS2020<br>
[Deepgcns: Can gcns go as deep as cnns?](https://openaccess.thecvf.com/content_ICCV_2019/html/Li_DeepGCNs_Can_GCNs_Go_As_Deep_As_CNNs_ICCV_2019_paper.html) -ICCV2019<br>
[Heterogeneous graph attention network](https://arxiv.org/abs/1903.07293) -WWW2019<br>
[Contextual Stroke Classification in Online Handwritten Documents with Graph Attention Networks](https://ieeexplore.ieee.org/abstract/document/8978003) -ICDAR2019<br>
[Graph Convolutional Networks for Text Classification](https://ojs.aaai.org/index.php/AAAI/article/view/4725) -AAAI2019<br>
[Graph Attention Networks](https://arxiv.org/abs/1710.10903) -ICLR2018<br>
[Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907) -ICLR2017<br>
